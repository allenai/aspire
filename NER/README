FILES & USAGE

-----------------------
extract_entities.py:

Extracts entities using PURE's Entity model.
1. Clone PURE project in a subdirectory named PURE under your aspire project.
2. Follow instructions in PURE/README.md:
    a. Install requirements in PURE/requirements.txt in SEPARATE environment
    (Has clashes with ASPIRE environment) and use this environment.
    b. Download SciBERT Entity model
3. Change values for CSFCUBE_DATA_PATH (rooth path to CSFCube)
    and BERT_MODEL_DIR (root path to SciBERT Entity model)
    inside extract_entities, and run.

-----------------------
evaluate.py:

Evaluate model on CFSdataset by predicting representations for all queries and candidates
and calculating similarities between them.

1. Use ASPIRE environment.
2. Configure params to select model name, facet, and optionally configs for CSFCube.
3. Run.
4. Result is similar to running pp_gen_nearest. I.e. run ranking_eval.py later to collect metrics.

-----------------------
eval_models.py

Contains implementations for all models used in experiment,
to perform evaluation on in evaluation.py.
Most of these implementation are wrappers to unify API calls.

Also contains factory method get_model(model_name) to instantiate Model Objects.

-----------------------
eval_datasets.py

Implementation of CSFCube dataset which also include NER data,
with ability to tune hyperparameters relating to extration of entities.

-----------------------
aspire_contextual_model.py

Alternative implementation of AspireConSent, which also adds representations
for entities, based on the tokens in their span in the original sentence they were in.
Used for the AspireContextual experiment.